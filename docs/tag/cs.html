<!DOCTYPE html>
<html lang="en">

<head>
    <title>The Critical Section - cs tag</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Pelican" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <link rel="stylesheet" href="/assets/main.css" />
    <link rel="icon" href="/assets/favicon.png" />
    <link href="https://fonts.googleapis.com/css?family=Roboto|Oswald|Open+Sans" rel="stylesheet">
</head>

<body onload="welcomeFunction()" >

  <header class="site-header" role="banner">
    <div class="wrapper">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> <!--An icon library for the button icon-->

      <a class="site-title" rel="author" href="/">The Critical Section</a>

      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
        </label>

        <div class="trigger">
            <a class="page-link" href="/about.html">About</a>
            <a class="page-link" href="/posts.html">Posts</a>
            <a class="page-link" href="/tags.html">Tags</a>
        </div>

      </nav>

    </div>
  </header>


  <main class="page-content" aria-label="Content">
    <div class="wrapper">
<h2>Articles tagged with cs</h2>




<p style="padding-top: 30px;">
Recent posts:
</p>

<ul>

    <li>
      <span class="dates_and_tags">11 Apr 2024 </span>
      
      
      <a class="enum_title" href="functional_dl.html"><b>Functional Deep Learning</b></a>
      
      <p>
      JAX, the functional automatic differentiation library from Google, has established itself as a highly useful deep learning tool. It stands in stark contrast with the OOP approach of Torch and offers an interesting perspective to how deep learning systems can be built in an entirely functional approach. In reality, the boundaries between Torch and Jax are blurry, as nowadays <code>flax</code> has features which look like the OOP style of Torch, while <code>functorch</code> mimics the features of Jax. Nonetheless, Jax was the first of its kind and still carries heavy momentum when it comes to new projects implemented with it. Let's explore it a bit.
      </p>
      <br>
    </li>


    <li>
      <span class="dates_and_tags">12 Mar 2024 </span>
      
      
      <a class="enum_title" href="marching_cubes.html"><b>Marching Cubes and Co</b></a>
      
      <p>
      The field of computer graphics contains some very nice and insightful algorithms. I wish I had explored them earlier, but it's still not that late. This post describes <em>marching cubes</em> - a ultra-simple algorithm for the extraction of a triangular mesh from a 3D field. This algorithm is widely applicable in all kinds of graphics applications, whether it is volumetric rendering of CT scans in healthcare, or tunnel/cave mapping in an industrial setting. It also combines well with the growingly-popular deep learning NeRF models. There it can be used to render a mesh from the 3D reconstruction.
      </p>
      <br>
    </li>


    <li>
      <span class="dates_and_tags">10 Feb 2024 </span>
      
      
      <a class="enum_title" href="basic_information_theory.html"><b>Information, Codes, and Content</b></a>
      
      <p>
      Information theory is the subfield of applied mathematics concerned with topics like information content, data compression, information storage and transmission. The key terms and concepts appear often in machine learning and I have found myself sometimes cross-referencing them from both disciplines. In this post, we cover some of the absolute basics - entropy, some simple codes, and limiting results. I think these ideas integrate nicely with other fields and are useful as a general background context for machine learning. Even more so, they are fundamental, due to how learning is inherently related to data compression.
      </p>
      <br>
    </li>


    <li>
      <span class="dates_and_tags">03 Dec 2023 </span>
      
      
      <a class="enum_title" href="deep_learning_at_scale.html"><b>Deep Learning at Scale</b></a>
      
      <p>
      As the scale of my ML projects started to increase, I have found myself in need of understanding more and more the actual engineering aspects around the models. I am perfectly fine with deep learning being an engineering-first discipline, rather than a theory-first one. Yet there are considerably more high-quality sources about the algorithms than about the implementation tricks needed. This post attempts to summarize important knowledge useful in understanding how to scale the modern deep learning approach to larger datasets, more nodes, and across different accelerators. Most likely, this is the first of multiple such posts.
      </p>
      <br>
    </li>


    <li>
      <span class="dates_and_tags">13 Sep 2023 </span>
      
      
      <a class="enum_title" href="mpeg.html"><b>Video Coding and MPEG</b></a>
      
      <p>
      I find the topics of image analysis and video compression very enjoyable. A previous <a href="https://aceofgreens.github.io/steganography_and_jpeg.html">post</a> has covered JPEG, the most widely used image compression standard. Now it's time to explore the <a href="https://en.wikipedia.org/wiki/Moving_Picture_Experts_Group#Standards">MPEG standards</a>, at least some of them. This is a super important topic, as videos are too large to store or stream across the internet in their raw format. So we necessarily need efficient compression algorithms. And there is some solid math, like the DCT, as well as various engineering tricks, like quantization and predictive coding, involved in them...
      </p>
      <br>
    </li>

</ul>


<figure>
    <img src = "/images/margulis_graph.svg" alt="Expander Graph" width="1000">
    <figcaption>Figure 1: An expander - a most curious sparse graph with strong connectivity properties.<br>Every subset of less than half the total number of vertices has a proportionally large boundary of edges.</figcaption>
</figure>


 
<div class="post-content e-content content" itemprop="articleBody"></div> 

    </div>
  </main>


<footer class="site-footer h-card">
  <div class="wrapper">
  
  <p></p>
  

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


    <div class="footer-col-wrapper">

      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The Critical Section</li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          <li><a href="https://github.com/aceofgreens"><i class="fa fa-github"></i> GitHub</a></li>


        </ul>
      </div>


      <div class="footer-col footer-col-3">
        <p>A personal blog for artificial intelligence and similar topics.</p>
      </div>
    </div>

  </div>
</footer>

<script type="text/javascript">
function welcomeFunction() {
  var items = document.getElementsByTagName("code");
    for (var i = items.length; i--;) {
      items[i].setAttribute("class", "highlight");
  }
}
</script>

</body>
</html>