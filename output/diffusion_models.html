<!DOCTYPE html>
<html lang="en">

<head>
    <title>Generative Models: Diffusion | The Critical Section</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Pelican" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <link rel="stylesheet" href="/assets/main.css" />
    <link rel="icon" href="/assets/favicon.png" />
    <link href="https://fonts.googleapis.com/css?family=Roboto|Oswald|Open+Sans" rel="stylesheet">


    <meta name="description" content="Diffusion models have take the world by storm. They have proved able to learn complicated distributions with impressive accuracy, enough to have real-world general-purpose utility. Their widespread use in text-to-image models is now evident and, interestingly, is spreading to many other problem settings. I have purposefully waited quite some time for the hype to settle down. But now, when expectations are more realistic, it's time to explore these curious models and the real impact they have on the current state of deep learning." />

    <meta name="tags" content="ai" />

</head>

<body onload="welcomeFunction()" >

  <header class="site-header" role="banner">
    <div class="wrapper">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> <!--An icon library for the button icon-->

      <a class="site-title" rel="author" href="/">The Critical Section</a>

      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
        </label>

        <div class="trigger">
            <a class="page-link" href="/about.html">About</a>
            <a class="page-link" href="/posts.html">Posts</a>
            <a class="page-link" href="/tags.html">Tags</a>
        </div>

      </nav>

    </div>
  </header>


  <main class="page-content" aria-label="Content">
    <div class="wrapper">

  <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <header class="post-header">
      <h1 class="post-title p-name" itemprop="name headline">Generative Models: Diffusion</h1>
      <p class="post-meta">
        <time class="dt-published" datetime="2024-02-04T07:00:00+02:00" itemprop="datePublished">
          4 Feb 2024
        </time>
      </p>

    </header>

    <div class="post-content">
      <p>Diffusion models have take the world by storm. They have proved able to learn complicated distributions with impressive accuracy, enough to have real-world general-purpose utility. Their widespread use in text-to-image models is now evident and, interestingly, is spreading to many other problem settings. I have purposefully waited quite some time for the hype to settle down. But now, when expectations are more realistic, it's time to explore these curious models and the real impact they have on the current state of deep learning.</p>
<p>To begin, one should realize that denoising is intrinsically tied to generation. Adding noise to the data in most cases permanently destroys parts of the sample. If the scale of the noise is too big, at some point it overwhelms the useful signal rendering the resulting noisy sample indistinguishable from randomness. But in the reverse process of denoising the sample, you still have to produce those features which have been corrupted. Basic denoising methods such as mean or median filtering do not learn and hence the quality of their results is bounded by the noise levels. But other methods do learn. And if the noise levels are overwhelming, to the point where you don't see most of the clean features, the process of denoising becomes more and more like generation. This is the high-level intuition behind diffusion - we define a process which adds noise to the data, called the <em>forward process</em>, and train a parametric model to denoise it, this being the <em>reverse</em> process. At test time, we feed random noise to the model, which being trained to denoise <em>anything</em>, will transform this noise to a sample from the original data distribution.</p>
<p>Suppose we have a training dataset of samples and the underlying data distribution is <span class="math">\(\mathcal{D}\)</span>. The whole diffusion pipeline can be applied independently across all samples. For that reason, let's consider a single sample <span class="math">\(\textbf{x} \sim \mathcal{D}\)</span>. We can define a stochastic process which, at each step, adds noise to it. For simplicity, assume we add Gaussian noise independently to each dimension of the sample. If <span class="math">\(\textbf{x}\)</span> is an image, we'd add independent noise to the intensity of each pixel. If <span class="math">\(\textbf{x}\)</span> is a point in some geometric space, then we add noise to its coordinates. If <span class="math">\(\textbf{x}\)</span> represents a sample with physically-meaningful dimensions, we simply add noise to their measurements.</p>
<p>Doing this for multiple steps, we get a discrete random walk. One commonly and highly practical example definition for the stochastic process governing it is:</p>
<div class="math">$$
\begin{aligned}
\textbf{x}_{t+1} &amp; = \sqrt{1 - \beta_{t+1}}\textbf{x}_t + \sqrt{\beta_{t+1}}\epsilon_{t+1} \\
\epsilon_{t+1} &amp; \sim \mathcal{N}(0, \textbf{I}) \\
\Rightarrow \textbf{x}_{t+1} &amp; \sim \mathcal{N} \big(\sqrt{1 - \beta_{t+1}} \textbf{x}_t, \beta_{t+1} \textbf{I}\big).
\end{aligned}
$$</div>
<p>Here <span class="math">\(\textbf{x}_0\)</span> is the clean sample. The index <span class="math">\(t\)</span> indicates the time step for the random walk, which is typically limited to some upper range <span class="math">\(T\)</span>. The process is parameterized by a sequence <span class="math">\(\beta_1, ..., \beta_T\)</span> - usually some monotone function in <span class="math">\([0, 1]\)</span>. The previous noisy sample <span class="math">\(\textbf{x}_{t}\)</span> is scaled by <span class="math">\(\sqrt{1 - \beta_{t+1}}\)</span> which pushes it towards <span class="math">\(0\)</span>. If <span class="math">\(\textbf{x}\)</span> is properly normalized, the added noise is independent of its range of values, which is convenient.</p>
<p>This exact process is useful because it allows for a close-form calculation for the resulting distribution of <span class="math">\(\textbf{x}_t\)</span> after <span class="math">\(t\)</span> total steps. Thus, to compute <span class="math">\(\textbf{x}_{t+2}\)</span> from <span class="math">\(\textbf{x}_t\)</span> one does not need to simulate the process for two steps but can use appropriate formulas to get the distribution at <span class="math">\(t+2\)</span> directly:</p>
<div class="math">$$
\begin{aligned}
\textbf{x}_{t+2} &amp;= \sqrt{1 - \beta_{t+2}} \textbf{x}_{t+1} + \sqrt{\beta_{t+2}} \epsilon_{t+2} \\
&amp; = \sqrt{1 - \beta_{t+2}} \big (\sqrt{1 - \beta_{t+1}} \textbf{x}_{t} + \sqrt{\beta_{t+1}} \epsilon_{t+1} \big) + \sqrt{\beta_{t+2}} \epsilon_{t+2} \\
&amp;= \sqrt{1 - \beta_{t+2}} \sqrt{1 - \beta_{t+1}} \textbf{x}_{t} + \sqrt{1 - \beta_{t+2}} \sqrt{\beta_{t+1}} \epsilon_{t+1} + \sqrt{\beta_{t+2}} \epsilon_{t+2} \\
&amp; \sim \mathcal{N} \Big (\sqrt{\prod_{i = 1}^2 (1 - \beta_{t+i})}\textbf{x}_t, \ \big(1 - \prod_{i=1}^2 (1 - \beta_{t+i}) \big)\textbf{I} \Big).
\end{aligned}
$$</div>
<p>In general, for any <span class="math">\(t\)</span> the distribution is given by</p>
<div class="math">$$
\textbf{x}_{t} \sim \mathcal{N} \big (\sqrt{\bar{\alpha}_t}\textbf{x}_0, \ (1 - \bar{\alpha}_t )\textbf{I} \big),
$$</div>
<p>where we have set <span class="math">\( \alpha_t = 1 - \beta_t\)</span> and <span class="math">\(\bar{\alpha}_t = \prod_{i=1}^t \alpha_i\)</span> for convenience. Another useful property is that under some mild conditions on the variance schedule <span class="math">\(\beta_i\)</span>, the distribution of <span class="math">\(\textbf{x}_t\)</span> converges to an isotropic Gaussian as <span class="math">\(T \rightarrow \infty\)</span>. More generally <span class="math">\(\textbf{x}_{1:T} | \textbf{x}_0\)</span> is a Guassian process and hence <span class="math">\(\textbf{x}_{t-1} | \textbf{x}_t, \textbf{x}_0\)</span> is also Gaussian. However, the quantity of interest <span class="math">\(\textbf{x}_{t-1} | \textbf{x}_{t}\)</span> is not Gaussian. It's approximately Gaussian if the <span class="math">\(\beta_i\)</span> parameters are small. Crucially, the mean and standard deviation of this Gaussian depend on the whole dataset and this is where learning comes in.</p>
<p>So, we construct a neural network <span class="math">\(p_\theta\)</span> that takes in <span class="math">\((\textbf{x}_t, t)\)</span> and outputs the mean and standard deviation of <span class="math">\(\textbf{x}_{t-1} | \textbf{x}_{t}\)</span>. By autoregressively calling our network, we get samples from the joint distribution <span class="math">\(p_\theta(\textbf{x}_{0:T}) = p(\textbf{x}_T) \prod_{t=1}^T p_\theta(\textbf{x}_{t-1} | \textbf{x}_{t})\)</span>. Since we don't care about the intermediate samples, our only task is to learn the network parameters <span class="math">\(\theta\)</span> such that <span class="math">\(p_\theta(\textbf{x}_0) \approx p(\textbf{x}_0)\)</span>. Similar to a VAE, one can use variational inference here.</p>
<p>So, <span class="math">\(p(\textbf{x}_0)\)</span> is the observed target distribution, <span class="math">\(p(\textbf{x}_{1:T} | \textbf{x}_0)\)</span> is the latent distribution. We denote the trainable model as <span class="math">\(p_\theta\)</span> and hence its latent distribution is <span class="math">\(p_\theta(\textbf{x}_{1:T} | \textbf{x}_0)\)</span>. Then,</p>
<div class="math">$$
\begin{align*}
\ln p_{\theta}(\textbf{x}_0) &amp;= \ln \int p_{\theta}(\textbf{x}_{0:T}) \frac{p(\textbf{x}_{1:T} | \textbf{x}_0)}{p(\textbf{x}_{1:T} | \textbf{x}_0)} d\textbf{x}_{1:T} \\
&amp;= \ln \mathbb{E}_{\textbf{x}_{1:T} \ \sim \ p} \Big[\frac{p_\theta (\textbf{x}_{0:T})}{p(\textbf{x}_{1:T} | \textbf{x}_0)} \Big] \\
&amp; \ge \mathbb{E}_{\textbf{x}_{1:T} \ \sim \ p} \Big[ \ln \frac{p_\theta (\textbf{x}_{0:T})}{p(\textbf{x}_{1:T} | \textbf{x}_0)} \Big] = \mathbb{E}_{\textbf{x}_{1:T} \ \sim \ p} \Big[ \ln p_\theta(\textbf{x}_{0:T}) - \ln p(\textbf{x}_{1:T} | \textbf{x}_0) \Big] \\
&amp; \Rightarrow \mathbb{E}_{\textbf{x}_0 \ \sim \ p} \big[ \ln p_\theta (\textbf{x}_0)\big] \ge \mathbb{E}_{\textbf{x}_{0:T} \sim p} \big[\ln p_\theta (\textbf{x}_{0:T}) - \ln p (\textbf{x}_{1:T} | \textbf{x}_0)\big].
\end{align*}
$$</div>
<p>Thus, instead of maximizing the likelihood of the observed data, we maximize a lower bound, the ELBO. Now from the last expression we can pick out only those terms that depend on <span class="math">\(\theta\)</span>. Given that <span class="math">\(p_\theta(\textbf{x}_T) = \mathcal{N}(\textbf{0}, \textbf{I})\)</span>, we formulate the following loss function:</p>
<div class="math">$$
\mathcal{L}(\theta) = \sum_{t = 1}^T \mathbb{E}_{\textbf{x}_{t-1}, \textbf{x}_t \sim p} \big[ - \ln p_\theta(\textbf{x}_{t-1} | \textbf{x}_{t} )\big]
$$</div>
<p>Now, we need <span class="math">\(p_\theta(\textbf{x}_{t-1} | \textbf{x}_t)\)</span> to be something easy to evaluate, like a Gaussian. But <span class="math">\(\textbf{x}_{t-1} | \textbf{x}_t\)</span> does not have a Gaussian distribution, <span class="math">\(\textbf{x}_{t-1} | \textbf{x}_t, \textbf{x}_0\)</span> does. So we need to have the model estimate <span class="math">\(\textbf{x}_0\)</span>. In practice, we can easily get <span class="math">\(\textbf{x}_0\)</span> since it is related to <span class="math">\(\textbf{x}_t\)</span> through the noise <span class="math">\(\epsilon_t\)</span>,</p>
<div class="math">$$
\textbf{x}_t = \sqrt{\bar{\alpha}_t} \textbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon_t \Longleftrightarrow \textbf{x}_0 = \frac{\textbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \epsilon_t}{\sqrt{\bar{\alpha}}_t},
$$</div>
<p>so in fact we can have the network predict the noise, obtaining <span class="math">\(\epsilon_\theta(\textbf{x}_t, t)\)</span>. Once we have an estimate of the noise, we essentially have an estimate of <span class="math">\(\textbf{x}_0\)</span> and in turn can evaluate <span class="math">\(\textbf{x}_{t-1} | \textbf{x}_t, \textbf{x}_0\)</span>. The variance is usually fixed to some constant as predicting it introduces instability. The formula for the estimated mean is </p>
<div class="math">$$
\mu_{\theta}(\textbf{x}_{t-1} | \textbf{x}_t) = \frac{1}{\sqrt{\bar{\alpha}_t}} \big(\textbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t} \epsilon_t} \epsilon_{\theta}(\textbf{x}_t, t) \big).
$$</div>
<p>This is roughly how denoising diffusion probabilistic models (DDPM) work [1]. At training time the network learns to estimate the noise. At test time, we start with a single sample <span class="math">\(\textbf{x}_T\)</span> from the prior, a Gaussian, call the model to obtain <span class="math">\(\epsilon_\theta(\textbf{x}_T)\)</span>, compute <span class="math">\(\mu_\theta(\textbf{x}_{T-1} | \textbf{x}_T)\)</span> analytically and sample <span class="math">\(\textbf{x}_{T-1}\)</span> from the estimated distribution of <span class="math">\(\textbf{x}_{T-1} | \textbf{x}_T\)</span>. Repeat autoregressively until we get to <span class="math">\(\textbf{x}_0\)</span>. Note that because of the intermediate sampling, even it we start from the same noisy <span class="math">\(\textbf{x}_T\)</span> multiple times, we will always get different generated samples.</p>
<h3>Score-Based Generative Modeling</h3>
<p>There is another diffusion formulation which is quite intuitive - that of score matching. Given a distribution <span class="math">\(p(\textbf{x})\)</span>, the score <span class="math">\(s(\textbf{x})\)</span> is simply the gradient of the log-likelihood, <span class="math">\(\nabla_\textbf{x} \ln p(\textbf{x})\)</span>. It's an attractive quantity because it doesn't require calculating any intractable normalization constants. But how is it related to sample generation?</p>
<p>One usage of the score is in <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_Langevin_dynamics">stochastic gradient Langevin dynamics (SGLD)</a>, a curious, perhaps even beautiful, method for sampling from physics/thermodynamics. Suppose we start from a sample <span class="math">\(\textbf{x}_0\)</span>. To, get a sample from the target distribution <span class="math">\(p(\textbf{x})\)</span> we can simply do log-likelihood ascent, with added noise injection:</p>
<div class="math">$$
\begin{align}
\textbf{x}_t &amp;= \textbf{x}_{t-1} + \frac{\delta}{2} \nabla_\textbf{x} \ln p(\textbf{x}_{t-1}) + \sqrt{\delta} \epsilon_t, \\
\epsilon_t &amp; \sim \mathcal{N}(\textbf{0}, \textbf{I}).
\end{align}
$$</div>
<p>Overall this very closely resembles gradient ascent. As long as <span class="math">\(t \rightarrow \infty\)</span> and <span class="math">\(\epsilon \rightarrow \textbf{0}\)</span>, <span class="math">\(\textbf{x}_t\)</span> will be a sample from <span class="math">\(p(\textbf{x})\)</span>. The added noise at each step is necessary, otherwise the sequence will converge to a local minimum and will depend on the starting location. So if we train a model for the score, <span class="math">\(s_\theta(\cdot)\)</span>, we can just plug it in the Langevin equation and iterate to get a sample. This is the inference approach of score-based sample generation.</p>
<p>The training process here is called <em>score matching</em> because the network attempts to accurately match the true score. Similarly to DDPMs, one needs to define a finite sequence of noise scales which are used to perturb the input samples. However, it's useful to see also the case where the diffusion time is continuous [2]. Suppose <span class="math">\(t\)</span> is continuous and in <span class="math">\([0, T]\)</span>. The forward process adding noise to the data can now be modeled as the SDE</p>
<div class="math">$$
d\textbf{x} = f(\textbf{x}, t) dt + g(t) d\textbf{w},
$$</div>
<p>where <span class="math">\(f(\textbf{x}, t)\)</span> is the drift term, <span class="math">\(g(t)\)</span> is a diffusion term, and <span class="math">\(\textbf{w}\)</span> is a Wiener process. For simplicity, the diffusion term is a scalar, not depending on <span class="math">\(\textbf{x}\)</span>. This is a general formulation. Given this, it is a known mathematical fact that there exists a reverse diffusion process, modeled by a reverse SDE:</p>
<div class="math">$$
d\textbf{x} = \big[ f(\textbf{x}, t) - g(t)^2 \nabla_\textbf{x} \ln p(\textbf{x}_t) \big] dt + g(t) d\bar{\textbf{w}}.
$$</div>
<p>Here <span class="math">\(dt\)</span> is a infinitesimal negative timestep and <span class="math">\(\bar{\textbf{w}}\)</span> is a Wiener process where time flows backward from <span class="math">\(T\)</span> to <span class="math">\(0\)</span>. As we can see, if we have the score, we can reverse the process. Thus, to learn the score, we construct a network <span class="math">\(s_\theta\)</span> that takes in <span class="math">\((\textbf{x}(t), t)\)</span> and is trained to solve the following <em>simplified</em> objective</p>
<div class="math">$$
\theta^{*} = \underset{\theta}{\arg\min} \ \  \mathbb{E}_t \Big[ \mathbb{E}_{\textbf{x}_0} \mathbb{E}_{\textbf{x}(t) | \textbf{x}(0)} \big[ {\lVert s_\theta(\textbf{x}(t), t) - \nabla_\textbf{x} \log p(\textbf{x}(t) | \textbf{x}(0)) \rVert}_2^2 \big] \Big].
$$</div>
<p>Note that here, depending on the exact SDE, <span class="math">\(p(\textbf{x}(t) | \textbf{x}(0))\)</span> may or may not be computable efficiently. If the drift coefficients are affine, then this probability is Gaussian and can be computed easily. For more advanced ones, one can use Kolmogorov's forward equation or simply simulate it.</p>
<figure>
    <img class='extra_big_img' src="/images/diff_sde.png" alt="Diffusion SDE" width="2000">
    <figcaption>Figure 1: A continuous time diffusion process. Left part shows the forward process which adds noise. Right part shows the inverse process which denoises. Image taken from <a href="https://arxiv.org/pdf/2011.13456.pdf">(Song, Y. 2020)</a>.</figcaption>
</figure>

<p>Consider the benefit of adding noise for training the score network. Without adding noise the ground-truth score can be evaluated only at the samples in the dataset. But the first sample <span class="math">\(\textbf{x}(T)\)</span> from the prior at test time may be very far from the data distribution. Hence, if you don't have data points around the space where your prior has high density your score estimate won't be accurate at those locations. To alleviate this, the forward diffusion effectively performs <em>annealing</em>. Adding the noise allows us to learn the score over a larger and more smooth region, covering the path from the data distribution to the prior one.</p>
<p>The DDPM model that we discussed above can written in both its discrete and continuous versions:</p>
<div class="math">$$
\begin{align}
\textbf{x}_{t+1} &amp;= \sqrt{1 - \beta_{t+1}}\textbf{x}_{t} + \sqrt{\beta_{t+1}} \epsilon_{t+1} \\
d\textbf{x} &amp;= -\frac{1}{2} \beta(t) \textbf{x} dt + \sqrt{\beta(t)}d \textbf{w}.
\end{align}
$$</div>
<p>Other discrete diffusion formulations also have similarly-looking continuous SDEs. But once we have trained the score network, how do we actually generate a sample using the reverse SDE? Well, we use a numerical SDE solver like the Euler-Maruyama or the stochastic Runge-Kutta. These solvers discretize the SDE in tiny steps and iterate in a manner similar to Langevin dynamics, adding a small amount of noise at every step.</p>
<p>Importantly, it can be proved that the DDPMs and the score-based methods are <em>equivalent</em> [3]. It takes some math to see this, but at the end one can reparametrize the DDPM to produce scores. In fact, the relation is relatively simple: <span class="math">\(\nabla_{\textbf{x}_t} \log p(\textbf{x}_t)  = - \epsilon_\theta(\textbf{x}_t, t) / \sqrt{1 - \bar{\alpha}_t}\)</span>. The formulas and the loss function are adjusted accordingly. This produces a unified perspective - the network can use the noisy <span class="math">\((\textbf{x}_t, t)\)</span> to predict either <span class="math">\(\textbf{x}_0\)</span>, or <span class="math">\(\epsilon_t\)</span>, or <span class="math">\(\nabla_\textbf{x} \log p(\textbf{x}_t)\)</span> - all will work, but will require different denoising formulas for the test time refinements.</p>
<h3>Practical Considerations</h3>
<p>Naturally, to be able to learn <span class="math">\(\epsilon_t\)</span>, <span class="math">\(\textbf{x}_0\)</span>, or <span class="math">\(\nabla_\textbf{x} \log p(\textbf{x}_t)\)</span>, especially when <span class="math">\(\textbf{x}\)</span> is very high-dimensional, one needs to have a big model. Denoising architectures with skip connections, like U-Nets, or pure transformer-based approaches, for example for non-image data, are the go-to choice. </p>
<p>Apart from model size, one needs to consider also the inference speed. With DDPMs you have to iterate from <span class="math">\(T\)</span> to <span class="math">\(1\)</span>, which in practice is simply too slow. One straightforward approach is to simply denoise once every <span class="math">\(S\)</span> steps, for a total of <span class="math">\(\lfloor T/S \rfloor\)</span> denoising calls. Since the model has learned to produce a meaningful output for all <span class="math">\((\textbf{x}_t, t)\)</span>, we are simply calling it <span class="math">\(S\)</span> times less, even though we are slightly biasing it. Another similar approach is given by denoising diffusion implicit models (DDIM) [4], which requires some effort to fully understand, but it's worth it.</p>
<p>To speed up the generation, one needs to come up with an inference process that simply uses less steps. The objective optimized by DDPM only depends on <span class="math">\(p(\textbf{x}_t | \textbf{x}_0)\)</span>, not on <span class="math">\(p(\textbf{x}_{1:T})\)</span>. In principle, there are many processes that have the same <span class="math">\(p(\textbf{x}_t | \textbf{x}_0)\)</span>, but may not be Markovian. This, in turn can be used to speed up the generation of new samples. One can consider the following:</p>
<div class="math">$$
\begin{align}
p_\sigma &amp;= p_\sigma(\textbf{x}_T | \textbf{x}_0) \prod_{t=2}^T p_\sigma(\textbf{x}_{t-1} | \textbf{x}_t, \textbf{x}_0) \\
p_\sigma(\textbf{x}_T | \textbf{x}_0) &amp;= \mathcal{N}(\sqrt{\bar{\alpha}_T} \textbf{x}_0, (1 - \bar{\alpha}_T)\textbf{I}) \\
p_\sigma(\textbf{x}_{t-1} | \textbf{x}_t, \textbf{x}_0) &amp;= \mathcal{N}(\sqrt{\bar{\alpha}_{t-1}} \textbf{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \cdot \Big(\frac{\textbf{x}_t - \sqrt{\bar{\alpha}_t}\textbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}}\Big), \sigma_t^2 \textbf{I} ).
\end{align}
$$</div>
<p>Here <span class="math">\(p_\sigma(\textbf{x}_t | \textbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t} \textbf{x}_0, (1 - \bar{\alpha}_t) \textbf{I})\)</span> which still matches DDPM in that it is easy to evaluate, however the "forward" process <span class="math">\(p_\sigma(\textbf{x}_t | \textbf{x}_{t-1}, \textbf{x}_0)\)</span> is no longer Markovian. The quantity <span class="math">\(\sigma\)</span> is an important parameter that controls the stochasticity of the forward process. For one exact <span class="math">\(\sigma\)</span>, we get DDPM, which is Markovian. If <span class="math">\(\sigma_t = 0, \forall t\)</span> the process becomes <em>deterministic</em>. Thus, DDIMs are a generalization of DDPMs because they support non-Markovian and even deterministic processes.</p>
<p>The generative model <span class="math">\(p_\theta\)</span> is constructed similarly to <span class="math">\(p_\sigma\)</span>. Sampling <span class="math">\(\textbf{x}_{t-1}\)</span> from <span class="math">\(\textbf{x}_t\)</span> is calculated as:</p>
<div class="math">$$
\textbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \Big( \frac{\textbf{x}_{t} - \sqrt{1 - \bar{\alpha}_t} \epsilon_\theta(\textbf{x}_t, t)}{\sqrt{\bar{\alpha}_t}} \Big) + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \cdot \epsilon_\theta(\textbf{x}_t, t) + \sigma_t \epsilon_t.
$$</div>
<p>Notice how here to generate <span class="math">\(\textbf{x}_{t-1}\)</span> you need to know both <span class="math">\(\bar{\alpha}_t\)</span> and <span class="math">\(\bar{\alpha}_{t-1}\)</span>. This means that you can have irregularly spaced <span class="math">\(\alpha_t\)</span> coefficients. All that matters is the current and the next one. Thus, DDIM allows one to define a forward process on only a small subset of timesteps from <span class="math">\(\{1, 2, ..., T\}\)</span>, which in turns greatly speeds up the reverse generative process. It does not require retraining, just changing the calculations during the generation phase.</p>
<p>Apart from DDIM, one can typically get a huge inference speed improvement by doing diffusion in a latent space, as opposed to for example the high dimensional sample space of images [5]. To train a latent diffusion model one uses an encoder, like a VQ-VAE or something similar, to map the clean input to a latent space. In the latent space we add noise and pass the noisy variable to a U-Net which denoises it. Subsequently, this variable is fed to a decoder which upsamples and decodes back into the modality of interest. It is common also to have additional modality-specific encoders for any data that will condition the diffusion process. A cross-attention block in the U-Net handles the conditioning.</p>
<figure>
    <img class='img' src="/images/ldm.png" alt="Diffusion SDE" width="2000">
    <figcaption>Figure 2: Architecture schematic of a latent diffusion model. Image taken from <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf">(Rombach, R. 2022)</a>.</figcaption>
</figure>

<p>This idea of latent diffusion is <em>incredibly</em> powerful. It allows diffusion to be used in, realistically, all kinds of contexts. Using separate encoders and decoders allows one to build multi-modal generative models that can condition one signal on any other and can produce any signal modality from any other. Consider a model like <a href="https://marigoldmonodepth.github.io/">Marigold</a> [6]. They take a latent diffusion model and finetune it on synthetic (image, depth) pairs. The encoder transforms both RGB and depth (itself treated as a grayscaled image) into the latent space. The decoder maps the latent into a depth image. The result is a strong diffusion model for depth prediction.</p>
<p>And as these systems become more multi-modal, the importance of accurate conditioning only grows. Suppose we want to generate an image conditional on a high-level semantic label <span class="math">\(y\)</span> and we are given a classifier <span class="math">\(f_\phi(\textbf{x}_t, t)\)</span> that uses the current noisy images. Then, the score of the joint distribution <span class="math">\(p(\textbf{x}_t, y)\)</span> is:</p>
<div class="math">$$
\begin{align}
\nabla_{\textbf{x}_t} \log p(\textbf{x}_t, y) &amp;= \nabla_{\textbf{x}_t} \log p(\textbf{x}_t) + \nabla_{\textbf{x}_t} \log p(y | \textbf{x}_t) \\
&amp; \approx \frac{1}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(\textbf{x}_t, t) + \nabla_{\textbf{x}_t} \log f_\phi(y | \textbf{x}_t) \\
&amp;=  \frac{1}{\sqrt{1 - \bar{\alpha}_t}} \big( \epsilon_\theta(\textbf{x}_t, t) - \sqrt{1 - \bar{\alpha}_t} \nabla_{\textbf{x}_t} \log f_\phi(y | \textbf{x}_t) \big).
\end{align}
$$</div>
<p>The second line results from a first-order Taylor approximation of <span class="math">\(\log p(y | \textbf{x}_t)\)</span>. Thus, to make our diffusion model condition on the semantics <span class="math">\(y\)</span>, one needs to adjust the model output by a scaled gradient of the classifier - simply use <span class="math">\(\epsilon_\theta(\textbf{x}_t, t) - \sqrt{1 - \bar{\alpha}_t} \nabla_{\textbf{x}_t} \log f_\phi(y | \textbf{x}_t)\)</span> instead of <span class="math">\(\epsilon_\theta(\textbf{x}_t, t)\)</span>. The interpretation is that now one learns the score of the joint distribution. This method is called <em>classifier guided</em> diffusion [7].</p>
<p>A slightly more popular approach is <em>classifier-free guidance</em>, where one does not have a separate classifier but instead uses the same model - sometimes conditioning on the signal <span class="math">\(y\)</span>, sometimes not [8]. This produces an implicit classifier. Its gradient is given by </p>
<div class="math">$$
\begin{align}
\nabla_{\textbf{x}_t} \log p(y | \textbf{x}_t) &amp;= \nabla_{\textbf{x}_t} \log p(\textbf{x}_t | y) - \nabla_{\textbf{x}_t} \log p(\textbf{x}_t | y = \emptyset) \\
&amp;= -\frac{1}{\sqrt{1 - \bar{\alpha}_t}}\big( \epsilon_\theta(\textbf{x}_t, y) - \epsilon_\theta(\textbf{x}_t, y=\emptyset) \big).
\end{align}
$$</div>
<p>One can then easily derive that the quantity to be used instead of <span class="math">\(\epsilon_\theta(\textbf{x}_t, t)\)</span> in the subsequent calculations becomes actually <span class="math">\((1 + w)\epsilon_\theta(\textbf{x}_t, t, y) - w \epsilon_\theta(\textbf{x}_t, t, y = \emptyset)\)</span>. We have added a weight <span class="math">\(w\)</span> which shows how much the model should focus on the semantics <span class="math">\(y\)</span> when generating the sample. The default value of <span class="math">\(1\)</span> works reasonable.</p>
<p>With text-to-image models conditioning on the prompt requires us to be more careful. One of the principal difficulties here is that only nouns can be decoded to explicit visual objects, compared to modifiers like adjectives, adverbs, and propositions which modify the appearance of objects or the positional relationships between them. Additionally, learning content and style separately has been somewhat possible, as there are methods which can do it, but it's far from a solved matter. A famous technique here is <em>textual inversion</em> [10] - one finetunes a latent diffusion model on a small set of target images of a specific object, along with captions like "A photo of a <span class="math">\(S_*\)</span>", where <span class="math">\(S_*\)</span> is the object. The model only learns the embedding for the token <span class="math">\(S_*\)</span> after which it can refer to it.</p>
<p>Regarding the cultural effects of AI-generated images, I believe the evidence speaks for itself. Depending on the prompt, these models can produce images that <em>can</em> realistically be considered artwork, sometimes being indistinguishable from actual paintings by human artists. Yes, one can flood the art market with tons of new generated images, rendering human art close to worthless, but so what? The end consumer will only benefit from this. Text-to-image AI models will likely reduce the elitist status of visual art and will force people to appreciate an image, or a painting, for its actual content, not for the career, name, or personality of its creator. We should value paintings only based on how much their visual pattens resonate with our own experiences. In that context, AI art <em>is</em> art, by whatever non-humancentric definiton we adopt. We should be optimistic, because the best artworks are yet to come... and they won'be envisaged by a human brain.</p>
<h3>References</h3>
<p>[1] Ho, Jonathan, Ajay Jain, and Pieter Abbeel. <a href="https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html">Denoising diffusion probabilistic models.</a> Advances in neural information processing systems 33 (2020): 6840-6851. <br>
[2] Song, Yang, et al. <a href="https://arxiv.org/abs/2011.13456">Score-based generative modeling through stochastic differential equations.</a> arXiv preprint arXiv:2011.13456 (2020). <br>
[3] Luo, Calvin. <a href="https://arxiv.org/abs/2208.11970">Understanding diffusion models: A unified perspective.</a> arXiv preprint arXiv:2208.11970 (2022). <br>
[4] Song, Jiaming, Chenlin Meng, and Stefano Ermon. <a href="https://arxiv.org/abs/2010.02502">Denoising diffusion implicit models.</a> arXiv preprint arXiv:2010.02502 (2020). <br>
[5] Rombach, Robin, et al. <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html">High-resolution image synthesis with latent diffusion models.</a> Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022. <br>
[6] Ke, Bingxin, et al. <a href="https://arxiv.org/abs/2312.02145">Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation.</a> arXiv preprint arXiv:2312.02145 (2023). <br>
[7] Dhariwal, Prafulla, and Alexander Nichol. <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/49ad23d1ec9fa4bd8d77d02681df5cfa-Abstract.html">Diffusion models beat gans on image synthesis.</a> Advances in neural information processing systems 34 (2021): 8780-8794. <br>
[8] Ho, Jonathan, and Tim Salimans. <a href="https://arxiv.org/abs/2207.12598">Classifier-free diffusion guidance.</a> arXiv preprint arXiv:2207.12598 (2022). <br>
[9] Gal, Rinon, et al. <a href="https://arxiv.org/abs/2208.01618">An image is worth one word: Personalizing text-to-image generation using textual inversion.</a> arXiv preprint arXiv:2208.01618 (2022).   </p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = "https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML";

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'], ['$', '$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div>
  
  <p class="post-meta">
    Tag: ai
  </p>

  </article>


    </div>
  </main>


<footer class="site-footer h-card">
  <div class="wrapper">
  
  <p></p>
  

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


    <div class="footer-col-wrapper">

      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The Critical Section</li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          <li><a href="https://github.com/aceofgreens"><i class="fa fa-github"></i> GitHub</a></li>


        </ul>
      </div>


      <div class="footer-col footer-col-3">
        <p>A personal blog for artificial intelligence and similar topics.</p>
      </div>
    </div>

  </div>
</footer>

<script type="text/javascript">
function welcomeFunction() {
  var items = document.getElementsByTagName("code");
    for (var i = items.length; i--;) {
      items[i].setAttribute("class", "highlight");
  }
}
</script>

</body>
</html>