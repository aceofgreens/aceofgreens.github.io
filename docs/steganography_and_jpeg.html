<!DOCTYPE html>
<html lang="en">

<head>
    <title>Steganography & JPEG | The Critical Section</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Pelican" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <link rel="stylesheet" href="/assets/main.css" />
    <link rel="icon" href="/assets/favicon.png" />
    <link href="https://fonts.googleapis.com/css?family=Roboto|Oswald|Open+Sans" rel="stylesheet">


    <meta name="description" content="In cryptography the phrase "security through obscurity" refers to any approach in the design of a communication system which tries to enforce the security of a message by hiding the system's implementation. Nowadays this is generally discouraged in favour of "security by design", i.e. security obtained by virtue of the underlying system's fundamental properties. Nonetheless, the obscurity approach is not entirely forgotten. In fact, it's alive and kicking in a small cryptography-related field called steganography. Here the whole idea is to hide the existence of a message in some kind of carrier medium. This post explores the specific case of digital image steganography, which tries to hide one image in another as well as detect the embedding of multiple images." />

    <meta name="tags" content="cs" />

</head>

<body onload="welcomeFunction()" >

  <header class="site-header" role="banner">
    <div class="wrapper">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> <!--An icon library for the button icon-->

      <a class="site-title" rel="author" href="/">The Critical Section</a>

      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
        </label>

        <div class="trigger">
            <a class="page-link" href="/about.html">About</a>
            <a class="page-link" href="/posts.html">Posts</a>
            <a class="page-link" href="/tags.html">Tags</a>
        </div>

      </nav>

    </div>
  </header>


  <main class="page-content" aria-label="Content">
    <div class="wrapper">

  <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <header class="post-header">
      <h1 class="post-title p-name" itemprop="name headline">Steganography &amp; JPEG</h1>
      <p class="post-meta">
        <time class="dt-published" datetime="2023-03-04T07:00:00+02:00" itemprop="datePublished">
          4 Mar 2023
        </time>
      </p>

    </header>

    <div class="post-content">
      <p>In cryptography the phrase "security through obscurity" refers to any approach in the design of a communication system which tries to enforce the security of a message by hiding the system's implementation. Nowadays this is generally discouraged in favour of "security by design", i.e. security obtained by virtue of the underlying system's fundamental properties. Nonetheless, the obscurity approach is not entirely forgotten. In fact, it's alive and kicking in a small cryptography-related field called <em>steganography</em>. Here the whole idea is to hide the existence of a message in some kind of carrier medium. This post explores the specific case of digital image steganography, which tries to hide one image in another as well as detect the embedding of multiple images.</p>
<p>In image steganography the carrier medium in which we hide information is the digital image. Theoretically, the setup closely resembles that of encryption [1, 2]. We have an original image <span class="math">\(a\)</span>, a hidden image <span class="math">\(c\)</span>, and an optional key <span class="math">\(k\)</span>, shared or otherwise. Let's say Alice wants to send a hidden image to Bob. She can compute a <em>stego-image</em> (basically the equivalent of a ciphertext) using an embedding function <span class="math">\(\text{Em}\)</span> with signature:</p>
<div class="math">$$
\text{Em}: \mathcal{C} \times \mathcal{A} \times \mathcal{K} \rightarrow \mathcal{C'} \\
\text{Em}(c, a, k) \mapsto c' \\
c \in \mathcal{C}, a \in \mathcal{A}, k \in \mathcal{K}, c' \in \mathcal{C'}.
$$</div>
<p><span class="math">\(\mathcal{C}\)</span> is the space of all images, from which the original image <span class="math">\(c\)</span> is taken. This is called a carrier or a <em>cover</em> image. <span class="math">\(\mathcal{A}\)</span> are all hidden images from which <span class="math">\(a\)</span> is taken, <span class="math">\(\mathcal{K}\)</span> are the optional keys to use, and <span class="math">\(\mathcal{C'}\)</span> are the stego-images - carrier images in which the hidden information has been embedded. One wants <span class="math">\(\mathcal{C} = \mathcal{C}'\)</span> so that the stego-image does not leak anything.</p>
<p>Once Bob receives the stego-image, he needs a way to extract the hidden information. Depending on the actual setup he may use a key <span class="math">\(K\)</span> when extracting:</p>
<div class="math">$$
\text{Ex}: \mathcal{C}' \times \mathcal{K} \rightarrow \mathcal{A} \\
\text{Ex}(c', k) \mapsto a \\
a \in \mathcal{A}, c' \in \mathcal{C}', k \in \mathcal{K}.
$$</div>
<p>Three main aspects define the steganography setup [1]:</p>
<ol>
<li><strong>Capacity</strong>, relates to how much information can be hidden in the carrier medium</li>
<li><strong>Security</strong>, relates to how easy it is for an eavesdropper to detect any of the hidden information. Achieving high security, along with high capacity are the main goals in steganography.</li>
<li><strong>Robustness</strong>, relates to how much modification can the stego medium withstand before any hidden information is destroyed. Achieving a high degree of robustness is the goal of watermarking, where removing some information is impossible without severely degrading the quality.</li>
</ol>
<p>Apart from embedding information in digital images, the other complementary task would be to detect them. This is called <em>steganalysis</em>. Most of the methods that we'll discuss next are easily detectable. That being said, here the intent is to provide a general classification of the different methods without delving into <em>too</em> much details.</p>
<p>An image can be treated as a spatial signal sampled in a rectangular regular grid of coordinates. We can either insert the hidden information directly in this spatial domain, or in the related frequency domain, which is a different representation of the same information. Here we'll see methods using both approaches.</p>
<h3>The Spatial Domain</h3>
<p>Probably the simplest spatial domain method is to hide information in the least significant bits (LSBs) of the carrier image. Suppose the carrier and the hidden information are both images represented as arrays of type <code>uint8</code>. Suppose the carrier image is of shape <span class="math">\((H, W, 3)\)</span>. Let's assume for simplicity that the hidden image is also of that shape, otherwise we can pad up to or downsize to that shape.</p>
<p>We have to decide how many of the LSBs in the original image we'll use for the hidden image. From some quick experiments I've decided that 4 bits from every element works best. This supports up to <span class="math">\(2^4 = 16\)</span> different color intensities both in the original and the hidden images. To implement this, we just take the 4 most significant bits from each element in the image-to-hide and insert them into the 4 least significant bits of the corresponding elements in the carrier. This can be efficiently computed for vectorized inputs like images using bitwise operations.</p>
<div class="highlight"><pre><span></span><code>def embed(x, y):
    &quot;&quot;&quot; Embeds image y into image x. &quot;&quot;&quot;
    carrier = x &amp; 11110000
    hidden_info = (y &amp; 11110000) &gt;&gt; 4
    stego_image = carrier | hidden_info
    return stego_image

def extract(x):
    &quot;&quot;&quot; Extracts hidden information from image x. &quot;&quot;&quot;
    hidden = (x &amp; 00001111) &lt;&lt; 4
    original = x &amp; 11110000
    return original, hidden
</code></pre></div>

<p>In the pseudocode above the number of hidden bits transferred to the carrier is hardcoded for simplicity to 4 in each element. This means that the stego-image which will be visible to everyone and the hidden image will have the same quality. In reality, it's more common to favour the quality of the stego-image, so it's more difficult to detect that any hidden image is present just by visual inspection. Figure 1 shows a stego-image hiding a completely different image in the 3 last bits of each of its pixel. It is clear as day that this approach deals with an obvious trade-off - we can either have a cover image with high details and a hidden message with low details, or vice versa. Notice how with just 3 bits per element, the hidden image still looks quite reasonable. Using more bits will improve the details and make the dark background more consistent and uniform, but only at the expense of a lower quality cover.</p>
<figure>
    <img class='extra_big_img' src="/images/stego_3.jpeg" alt="Steganography in the spatial domain" width="1200">
    <figcaption>Figure 1: Steganography in the spatial domain. We hide the first 3 bits of each element of a hidden image in the last 3 bits of each element of a cover image. The image is multi-channel, and the different colour channels do not change the conceptual idea in any way. Since the hidden image has values only between $0$ and $2^3$, making it very dark, just for the visualization we multiply them by $2^5$. </figcaption>
</figure>

<p>A different clever way to do steganography in the spatial domain is through the image intensity histogram [2, 3]. To motivate this method, assume our secret consists of <span class="math">\(K\)</span> bits, <span class="math">\(B = b_1b_2...b_K\)</span>. The image quality won't be decreased too much if we flip the least significant bit of every pixel. So we can do the following: we increase the intensity of all pixels with value greater than <span class="math">\(L\)</span> by <span class="math">\(1\)</span>. After this transformation there will be no pixels with value exactly <span class="math">\(L + 1\)</span> and the histogram will have an empty bin. This is where we can fit our message <span class="math">\(B\)</span>. We scan the image sequentially and whenever we find a pixel with value <span class="math">\(L\)</span>, we consider the next bit we want to hide. If it's <span class="math">\(1\)</span>, we increase that pixel by 1. Otherwise, we keep it as is.</p>
<p>The end result is that all pixels with intensity less than <span class="math">\(L\)</span> are unchanged. The number of pixels with value <span class="math">\(L\)</span> is equal to the number of zeros in <span class="math">\(B\)</span>, those with value <span class="math">\(L+1\)</span> equal the ones in <span class="math">\(B\)</span> and all pixels with greater intensity have their intensity increased by <span class="math">\(1\)</span>. With this method we can insert up to <span class="math">\(h(L)\)</span> bits, where <span class="math">\(h\)</span> is the image histogram. Hence, to maximize capacity, <span class="math">\(L\)</span> should be chosen as the mode of the histogram - the most frequent intensity.</p>
<p>As another benefit, this technique can be entirely reversible... after we make some additional modifications. In the setup presented so far, we change the cover image, although slightly, and this cannot be undone. Consider what happens to the pixels with intensity <span class="math">\(255\)</span>. When we add <span class="math">\(1\)</span> to them, they will overflow. To fix this, we find the <em>least</em> frequent intensity value, <span class="math">\(L'\)</span>, which is assumed greater than <span class="math">\(L\)</span> (otherwise the whole algorithm is mirrored). Now, we set all pixels with value <span class="math">\(L'\)</span> to zero, but we also save their coordinates, as well as the value <span class="math">\(L'\)</span> itself. This is called the <em>overhead</em> for later reconstruction.</p>
<p>To make the method entirely reversible we can pass this overhead info into the hidden message payload. As a result, the <em>effective</em> capacity is reduced, but we are able to reconstruct the cover image perfectly. This also answers the question of why <span class="math">\(L'\)</span> is the least frequent intensity - because any larger intensity would lead to a larger overhead and subsequently reduced capacity. In terms of the quality of the cover image, we can measure it using the peak-signal-to-noise ratio (PSNR) which is fairly high.</p>
<div class="math">$$
\text{PSNR} = 10 \log_{10} \Big(\frac{255 \times 255}{MSE} \Big) = 48.13 \text{dB}.
$$</div>
<p>This can be proved by noting that since any pixel is changed by at most <span class="math">\(1\)</span> in absolute value, the mean squared error is bounded, and hence the PSNR achieves a lower bound of about <span class="math">\(48\)</span>. The logarithmic scaling is a signal-processing convention and is used often when measuring "power-like" variables like intensity and energy. Just for comparison, the PSNR of the method where we replace the LSBs directly is about <span class="math">\(39.1 \text{dB}\)</span>.</p>
<p>Regarding the extraction, it's very similar to the embedding, but with inverse operations applied in the inverse order. We won't spend much time on it. The point is that this type of histogram-based steganography is reversible and provides an acceptable amount of capacity.</p>
<p>There are multiple improvements to the above method. First, one can use multi-channel images to increase the capacity tremendously. Second, one can use multiple maximal-minimal points <span class="math">\((L, L')\)</span> to increase the capacity even in a single channel. Thirdly, one can consider the histogram of adjacent pixel differences (across either rows or columns) which typically looks like a zero-centered Gaussian. Since adjacent pixels in a homogeneous region have a difference of <span class="math">\(0\)</span>, the zero bin in the histogram accumulates much more pixels than before, and hence more information can be inserted [4].</p>
<h3>The Frequency Domain</h3>
<p>In the frequency domain the image is represented by the amplitude coefficients of multiple sinusoidal waves of varying frequencies which when added together reconstruct our image. It is known that the human visual system is more sensitive to lower frequency variations than to high ones. Additionally, the pixels of finer details like edges and corners which are represented by higher frequency waves are typically uncorrelated with other nearby pixels, unlike those of low-frequency waves. This means that we can potentially hide information in the higher frequencies without reducing the quality of the stego-image perceptibly.</p>
<p>We can use almost any transform to achieve our needs. However, only some have established themselves as a standard due to the various beneficial factors they possess. The most commonly used one is the <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">discrete cosine transform</a> (DCT) which is used <em>ubiquitously</em> in science and engineering. It represents a function as a sum of cosines and has very nice compression properties which we'll explore now.</p>
<p>Suppose we have a discrete sequence <span class="math">\((x_1, ..., x_N)\)</span>. If we fit a sum of sines and cosines to this sequence, we'll be able to evaluate it even outside of its left and right boundaries. That means that any Fourier-like transform operating on a finite domain implies a periodic extension to the original sequence, due to the periodicity of the sines and cosines. The DCT, where we use only cosines, implies an <em>even</em> extension.</p>
<p>At this point let's assume two important properties of the extended function:</p>
<ol>
<li>It is even at both the left and right boundaries <span class="math">\(x_1\)</span> and <span class="math">\(x_N\)</span>,</li>
<li>The point around which it is even is the midpoint between <span class="math">\(x_1\)</span> and the previous extended point.</li>
</ol>
<p>These two assumptions lead to an extended sequence </p>
<div class="math">$$
(..., x_N, ..., x_2, x_1, x_1, x_2, ..., x_N, x_N, x_{N-1}, ..., )
$$</div>
<p>where near the endpoints the points are copied, <span class="math">\((..., x_{N-1}, x_N, x_N, x_{N-1}, ...)\)</span>. Just for comparison, if our second assumption was that the extended sequence was even around exactly the boundary, then this would create sequences with less duplicated points <span class="math">\((..., x_{N-1}, x_N, x_{N-1}, ...)\)</span>. With the specific assumptions as defined above, the most common DCT type, DCT-II, is defined:</p>
<div class="math">$$
\begin{aligned}
X_k &amp; = e_k \sum_{n=0}^{N-1} x_n \cos \Big[\frac{\pi}{N} \big(n + \frac{1}{2}\big) k \Big], \ \text{ for all } k=0, ..., N-1 \\
x_n &amp; = \frac{2}{N} \sum_{k=0}^{N-1} e_k X_k  \cos \Big[\frac{\pi}{N} \big(n + \frac{1}{2}\big) k \Big], \ \text{ for all } n=0, ..., N-1 \\
e_k &amp; = \begin{cases}
\frac{1}{\sqrt{2}}, &amp; k = 0 \\
1, &amp; \text{otherwise.}
\end{cases}
\end{aligned}
$$</div>
<p>Here <span class="math">\(x_n\)</span> is the signal in the spatial domain at index <span class="math">\(n\)</span> and <span class="math">\(X_k\)</span> is the value of the DCT, or the <em>strength</em>, at the frequency multiple <span class="math">\(k\)</span>. The first equation is the forward transform, often called <em>analysis</em>, and the second one is the inverse, often called <em>synthesis</em>. The various multiplicative constants are more or less a convention and can vary across authors. As a sanity check, consider what the strength of the <span class="math">\(0\)</span>-th frequency, which is <span class="math">\(X_0 = \frac{1}{\sqrt{2}} \sum_{n=0}^{N - 1} x_n\)</span>. If we reconstruct the signal using only this frequency, we get <span class="math">\(\frac{1}{N} \sum_{n=0}^{N-1} x_n\)</span> -  the mean of the entire signal.</p>
<p>Apart from DCT-II, there are many other variants, depending on whether the function is even/odd on the left/right boundary and around which point exactly. Note that unlike the discrete Fourier transform, here the coefficients are entirely real. There's something deeper going on though. <strong>Functions which can be represented with fewer sinusoidal terms tend to be more compressible than those requiring many terms.</strong> And which functions require many terms? Those that have rapidly changing peaks and discontinuities. And often discontinuities come from the boundaries of the sequence.</p>
<p>Consider what happens with an odd extended function. We might have <span class="math">\((..., x_{N-1}, x_{N}, -x_{N}, -x_{N-1}, ...)\)</span> or <span class="math">\((..., x_{N}, 0, -x_N, ...)\)</span> where essentially <span class="math">\(f(-x) = -f(x)\)</span>. If <span class="math">\(f(x)\)</span> doesn't change sign within <span class="math">\((x_1, ..., x_N)\)</span>, then it surely changes sign at the boundaries <span class="math">\(1\)</span> and <span class="math">\(N\)</span> and this introduces discontinuities, reducing the rate of convergence of the series. This is why the discrete Fourier transform or the discrete sine transforms are not particularly favourable for compression - because their extended function is odd, which adds discontinuities and increases the number of required terms for any given level of accuracy. Whereas with the DCT-II the extension is always continuous at the boundaries.</p>
<p>The DCT can be trivially extended to two-dimensional signals and it's what we'll use here. We change the notation slightly, letting <span class="math">\(f(x, y)\)</span> be the image and <span class="math">\(F(u, v)\)</span> be the DCT. <span class="math">\(u\)</span> and <span class="math">\(v\)</span> are the spatial frequency multiples.</p>
<div class="math">$$
\begin{aligned}
F(u, v) &amp; = e_u e_v \sum_{x=0}^{N-1} \sum_{y=0}^{N-1} f(x, y) \cos \Big[\frac{\pi}{N} \big(x + \frac{1}{2}\big) u \Big]   \cos \Big[\frac{\pi}{N} \big(y + \frac{1}{2}\big) v \Big] \\
f(x, y) &amp; = \frac{2}{N} \sum_{u=0}^{N-1} \sum_{v=0}^{N-1} e_u e_v F(u, v)  \cos \Big[\frac{\pi}{N} \big(x + \frac{1}{2}\big) u \Big] \cos \Big[\frac{\pi}{N} \big(y + \frac{1}{2}\big) v \Big] \\
e_x &amp; = \begin{cases}
\frac{1}{\sqrt{2}}, &amp; x = 0 \\
1, &amp; \text{otherwise.}
\end{cases}
\end{aligned}
$$</div>
<p>One of the biggest applications of the DCT is in <a href="https://en.wikipedia.org/wiki/JPEG#">JPEG</a>, the famous algorithm for lossy compression of digital images. It was introduced in 1992 and to this day it's the most popular image compression method in the world. The image format JPEG along with other formats like JFIF are based on it. Let's take a look at how it works:</p>
<ol>
<li>The image is converted from RGB to <a href="https://en.wikipedia.org/wiki/YCbCr#">Y'CbCr</a>. This colour space disentangles the three channels into one luma channel - how bright a pixel is - and two chroma channels - what colour the pixel has. The luma channel Y' is more or less a gray-scaled version of the image and encodes the light intensity non-linearly using <a href="https://en.wikipedia.org/wiki/Gamma_correction">gamma-corrected</a> RGB primaries. The Cb is a "difference-blue" chroma channel which measures the difference between blue and the luminance. Similarly, Cr is "difference-red".</li>
<li>In the Y'CbCr space, <a href="https://en.wikipedia.org/wiki/Chroma_subsampling">chroma subsampling</a> is performed. This downsamples the Cb and Cr channels typically by a factor of 2 in both horizontal and vertical directions. What justifies the downsampling is the fact that the human visual system is more sensitive to luma changes than to chroma changes and there's no point in carrying around information which is almost imperceptible.</li>
<li>The Y', Cb, and Cr channels are further split into multiple blocks of size <span class="math">\(8 \times 8\)</span>. Each block is normalized into the range <span class="math">\([-128, 127]\)</span> and then for each channel in that block, the DCT is calculated. At this point each block contains its DCT coefficients. Storing them may temporarily require more than 8 bits, but this is alleviated in the next step.</li>
<li>Human vision is such that it's easier to differentiate between two similar brightness settings over a large region, than over a small high-frequency one. We cannot distinguish between <span class="math">\(256\)</span> different brightness levels for a small path of pixels, but perhaps just <span class="math">\(8\)</span>. For that reason, the next step is to quantize the DCT coefficients. Each coefficient from the <span class="math">\(8 \times 8\)</span> block is divided by a positive number which depends on the desired quality, and is then rounded to the nearest integer. The divisors are typically larger for those DCT coefficients corresponding to higher frequencies. <em>Many</em> of the coefficients may be <span class="math">\(0\)</span> after rounding. This is the main step of information loss in the algorithm.</li>
<li>Finally, the quantized DCT coefficients are stored as a sequence of bits. How exactly does this happen? For the current block, we iterate over all the coefficients in a zig-zag manner (similar to how the rational numbers can be enumerated). This essentially creates a sequence of 64 numbers with only some of them being non-zero. The zig-zaggy ordering ensures that long subsequences of zeros are created. Then this entire sequence is transformed using a run-length coding scheme. As an example, a sequence "AAAABBCCCCCC" can be encoded as "4A2B6C" saving up 6 symbols. After this step we end up with a shorter sequence of tuples containing information like how many zeros are before a given non-zero coefficient, how many bits are needed to express the coefficient and its actual value. Finally, <a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman coding</a> is used to shorten this even more. This is a variable-length scheme which further encodes more frequent elements with shorter codewords. This coding is what constitutes the JPEG file.</li>
</ol>
<figure>
    <img class='extra_big_img' src="/images/jpeg_compression.png" alt="JPEG compression" width="1200">
    <figcaption>Figure 2: JPEG compression. For each level of the desired quality a separate quantization table is used. The compression ratios typically vary around 10:1. </figcaption>
</figure>

<p>The decoding is basically the reverse process above, where we are able to reconstruct all data except that lost in the quantization step which is forever lost.</p>
<p>Finally, getting back to steganography, a clever way is to insert our hidden data into the LSBs of the non-zero quantized DCT coefficients after step 4. They will then be run-length and Huffman encoded together with the cover image bits into a proper JPEG file. This is what the JSteg algorithm does.</p>
<p>Beyond JSteg, there are many other algorithms which improve the various aspects of the steganographic process. Some algorithms select the DCT coefficients in which to embed the data randomly [6], others use the discrete wavelet transform (DWT) instead of the DCT. A third group use encryption of the hidden data to add an extra layer of security. In general, there is an abundance of methods which compete and improve upon each other.</p>
<h3>References</h3>
<p>[1] Provos, N. and Honeyman, P. <a href="https://ieeexplore.ieee.org/abstract/document/1203220">Hide and seek: an introduction to steganography</a> <em>IEEE Security &amp; Privacy</em>, vol. 1, no. 3, pp. 32-44 (2003). <br>
[2] Cheddad, A., Condell, J., Curran, K. and Kevitt, P. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0165168409003648">Digital image steganography: Survey and analysis of current methods</a> <em>Signal Processing</em>, vol. 90, issue 3, pp. 727-752 (2010). <br>
[3] Ni, Z., Shi, Y. Q., Ansari, N., Su, W. <a href="https://web.njit.edu/~ansari/papers/06TCAS.pdf">Reversible Data Hiding</a> <em>IEEE Trans. Circuits and Systems for Video Technology</em>, 16(3) 354-362, (2006). <br>
[4] Li, Z., Chen, X., Pan, X. and Zeng, X. <a href="https://ieeexplore.ieee.org/document/4769535">Lossless Data Hiding Scheme Based on Adjacent Pixel Difference</a> <em>International Conference on Computer Engineering and Technology</em>, Singapore, 2009, pp. 588-592 (2009). <br>
[5] Subhedar, M. S., Mankar, V. H. <a href="https://www.sciencedirect.com/science/article/abs/pii/S1574013714000136">Current status and key issues in image steganography: A survey</a> <em>Computer Science Review</em>, vol. 13–14, pp. 95-113 (2014). <br>
[6] Westfeld, A. <a href="https://link.springer.com/chapter/10.1007/3-540-45496-9_21">F5 - a steganographic algorithm: High capacity despite better steganalysis</a> <em>Proc. of the 4th Information Hiding Workshop</em>, vols. 21–37, pp. 289–302 (2001).   </p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = "https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML";

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'], ['$', '$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div>
  
  <p class="post-meta">
    Tag: cs
  </p>

  </article>


    </div>
  </main>


<footer class="site-footer h-card">
  <div class="wrapper">
  
  <p></p>
  

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">


    <div class="footer-col-wrapper">

      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The Critical Section</li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          <li><a href="https://github.com/aceofgreens"><i class="fa fa-github"></i> GitHub</a></li>


        </ul>
      </div>


      <div class="footer-col footer-col-3">
        <p>A personal blog for artificial intelligence and similar topics.</p>
      </div>
    </div>

  </div>
</footer>

<script type="text/javascript">
function welcomeFunction() {
  var items = document.getElementsByTagName("code");
    for (var i = items.length; i--;) {
      items[i].setAttribute("class", "highlight");
  }
}
</script>

</body>
</html>